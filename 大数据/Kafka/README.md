# 《深入理解Kafka核心设计与实现原理》

## 第1章 初识Kafka

### 1.1 基本概念

### 1.2 安装与配置

### 1.3 生产与消费

### 1.4 服务端参数配置

### 1.5 总结

## 第2章 生产者

### 2.1 客户端开发

### 2.2 原理分析

### 2.3 重要的生产者参数

### 2.4 总结

## 第3章 消费者

### 3.1 消费者与消费组

### 3.2 客户端开发

### 3.3 总结

## 第4章 主题与分区

### 4.1 主题的管理

### 4.2 初识KafkaAdminClient

### 4.3 分区的管理

### 4.4 如何选择合适的分区数

### 4.5 总结

## 第5章 日志存储

### 5.1 文件目录布局

### 5.2 日志格式的演变

### 5.3 日志索引

### 5.4 日志清理

### 5.5 磁盘存储

有关测试结果表明， 一个由6块7200r/min的RAID-5阵列组成的磁盘簇的线性（顺序）写 入速度可以达到600MB/s, 而随机写入速度只有lOOKB/s, 两者性能相差6000倍。 操作系统可
以针对线性读写做深层次的优化，比如预读(read-ahead, 提前将一个比较大的磁盘块读入内存） 和后写(write-behind, 将很多小的逻辑写操作合并起来组成一个大的物理写操作）技术。 顺序 写盘的速度不仅比随机写盘的速度快， 而且也比随机写内存的速度快


- 5.5.1 页缓存
- 5.5.2 磁盘 1/0 流程
- 5.5.3 零拷贝

### 5.6 总结

## 第6章 深入服务端

### 6.1 协议设计

### 6.2 时间轮

### 6.3 延时操作

### 6.4 控制器

### 6.5 参数解密

### 6.6 总结

## 第7章 深入客户端

### 7.1 分区分配策略

### 7.2 消费者协调器和组协调器

### 7.3__consumer_offsets剖析

### 7.4 事务

### 7.5 总结

## 第8章 可靠性探究

### 8.1 副本剖析

### 8.2 日志同步机制

### 8.3 可靠性分析

### 8.4 总结

## 第9章 Kafka应用

### 9.1 命令行工具

### 9.2 Kafka Connect

### 9.3 Kafka Mirror Maker

### 9.4 Kafka Streams

### 9.5 总结

## 第10章 Kafka监控

### 10.1 监控数据的来源

### 10.2 消费滞后

### 10.3 同步失效分区

### 10.4 监控指标说明

### 10.5 监控模块

### 10.6 总结

## 第11章 高级应用

### 11.1 过期时间（TTL）

### 11.2 延时队列

### 11.3 死信队列和重试队列

### 11.4 消息路由

### 11.5 消息轨迹

### 11.6 消息审计

### 11.7 消息代理

### 11.8 消息中间件选型

### 11.9 总结

## 第12章 Kafka与Spark的集成

### 12.1 Spark的安装及简单应用

### 12.2 Spark编程模型

### 12.3 Spark的运行结构

### 12.4 Spark Streaming简介

### 12.5 Kafka与Spark Streaming的整合

### 12.6 Spark SQL

### 12.7 Structured Streaming

### 12.8 Kafka与Structured Streaming的整合

### 12.9 总结

*XMind - Trial Version*